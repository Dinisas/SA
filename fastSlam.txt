The core challenge:
	to map the word accurately, the robot need to know where it is
	but to figure out where it is, the robot needs a good map of the world
The SLAM problem is the problem of determining the location of all landmarks θ and robot poses st from measurements zt and ut -> p(st, θ | zt, ut).


posterior probability distribution -> updated belief about the state of the world incorporating sensor measurements and control inputs. The robot's pose (its location and orientation) and the location of landmarks in the environment, so where it is and where things are around it up to that point based on the data gathered until then.

This paper presents
FastSLAM, an algorithm that recursively estimates the
full posterior distribution over robot pose and landmark
locations, yet scales logarithmically with the number of
landmarks in the map

This algorithm is based on an exact factorization of the posterior into a product of conditional landmark distributions and a distribution over
robot paths.

The ability to simultaneously localize a robot and
accurately map its environment is considered by many to be
a key prerequisite of truly autonomous robots

A key limitation of EKF-based approaches is their computational complexity. Sensor updates require time quadratic
in the number of landmarks K to compute. This complexity stems from the fact that the covariance matrix maintained
by the Kalman filters has O(K2
) elements, all of which must
be updated even if just a single landmark is observed. The
quadratic complexity limits the number of landmarks that
can be handled by this approach to only a few hundred—
whereas natural environment models frequently contain millions of features. 

In particular, the robot
poses, denoted s1, s2, . . . , st, evolve over time as a function
of the robot controls, denoted u1, . . . , ut. Each of the landmark measurements, denoted z1, . . . , zt, is a function of the
position θk of the landmark measured and of the robot pose
at the time the measurement was taken.

In Fast SLAM:
we decompose the SLAM problem into a robot localization problem: 

And a collection of landmark estimation problems that are conditioned on the robot pose estimate

Each particle possesses K Kalman filters that estimate the K landmark
locations conditioned on the path estimate.. A naive implementation of this idea leads to an algorithm that requires O(MK) time, where M is the number of particles in the particle filter and K is the number of landmarks.

FastSLAM uses a special tree-based data structure (usually a form of a binary search tree or similar structure) to store and update the landmark estimates more efficiently within each particle -> O(M log K).

p(st, θ | zt, ut, nt) = p(st | zt, ut, nt)-> sampling of various paths (localization problem with particle (or hypothesis) filter) Yk p(θk | st, zt, ut, nt) -> measurement of landmarks of a given know path (mapping problem). Conditional independence property of the SLAM problem.

Thus, for M particles and K landmarks, there will be a total of KM Kalman filters, each of dimension 2 (for the two landmark coordinates).

A particle filter uses particle containing pose states and importance weights to represent a probability density function (pdf)

ROBOT POSE / LOCALIZATION PROBLEM:

The path estimator p(st | zt, ut, nt) using a modified particle filter. A particle filter provides us with a good approximation of the posterior even under non-linear motion kinematics. Using a Monte Carlo localization (MCL) localization algorithm.

Each particle (or hypothesis) is essentially an individual estimate of where the robot might be and how the map could look.
A sample is a hypothesis as to what the true world state may be at time t

St = {st[m]}m = {s[m]1, s[m]2, . . . , s[m]t}m. m-th particle in the set

St is a set of all the partciples/samples actively representing the posterior probability distribution. 

Where each particle st is a guess of the robot's path, so each particle carries the entire path the robot could have taken until now -> conditional indepedence, very important, if the path is know, the landmarks become indepedent (and landmark estimates). 

st[m] = robot path + landmarks estimates

problem:The number of particles needed to represent a posterior grows exponentially with the dimension of the state space!

UPDATING A BELIEF ABOUT A ROBOT'S POSE AND MAP (Particle Path Particle):

1) Prediction / SAMPLING:

We compute a new set of particles, the set St, by updating the new set set St−1 at time t−1 using the robot control ut and the measurement zt (calculo incremental)

SLAM is a probabilistic markov chain, the current state (robot's pose) depends only on the previous state and the current control input and not on any earlier states.

Each particle s[m}t-1 belonging to St-1 is used to generate a probabilistic guess of the robot's pose at time t s[m]t. We are assuming the previous particles approximate the correct posterior

s[m]t ∼ p(st | ut, s[m]t−1) -> probabilistic guess of robot's pose at time t, obtained from the probabilistic motion model (describes how the robot thinks and moves based on control commands, but because of real world wheel slippage, rough terrain, sensor noise, etc... if i move forward one meter, instead of being exactly at position X we are probably near position X, with some uncertainty), to take this into account we add some random noise so each particle ends up in a different place.

this new pose guess s[m]t is added to a temporary set of particles, with the full history of poses robot's path up to time t( we estimate the whole path not just the current pose)

sampling a new pose hypothesis using a motion model and new particle states
Proposal distribution -> best guess of where the robot might be before incorporating the latest measurement zt (new pose hypothesis) p(st| zt−1, ut, nt−1)

2) WEIGHING:
Now we have a temporary set o guessed particles, we know have to refine them based on well each particle explains the latest observation zt -> compose a weight

w[m]t =target distribution/proposal distribution =p(st,[m]| zt, ut, nt)/p(st,[m]| zt−1, ut, nt−1), where the proposal distribution is a guess of where the robot might be, before seeing the new sensor data

3) RESAMPLING / Correction Step:
Once all the particles are weighed you perform a resampling: randomly draw M new particles with replacement (favoring those that have higher weights): so that particles with higher weights are more likley to be pciked multiple times (more particles in tehe regions of higher likelihood)

SUMMARY:

-> You start with particles that reflect the robot’s past state.

-> You move each particle forward using the motion model and control input.

-> This gives you a temporary set of new particles — a “proposal” guess for where the robot is now.

-> Next, you'll use the new observation zt to weight these particles and resample (that part comes after this paragraph).

LANDMARK LOCATION ESTIMATION

FastSLAM represents the conditional landmark estimates p(θk | st, zt, ut, nt) in by Kalman filters. Since this estimate is conditioned on the robot pose, the Kalman filters are attached to individual pose particles in St

St = {st,[m], µ[m]1, Σ[m]1, . . . , µ[m]K (mean) , Σ[m]K (covariance)}m , mean (estimated location of the landmark, 2D vector -> (x,y)) and covariance (how uncertain we are of that position) of the gaussian representing the k-th landmark of the m-th particle

p(θk | st, zt, ut, nt) -> Bayes ∝ p(zt | θk, st, zt−1, ut, nt) p(θk | st, zt−1, ut, nt), assuming k landmark was observed at time t (knowing which landamrk was observed)
= new belief * prior belief

with a prior gaussian, a linearzied gaussian observation model through ekf, we get a posterior gaussian

Tradtional ekf slam, covariance matrix with 2K+3 , 3=coordinates of robot pose, 2=coordiantes x, y of each landmark
fast slam, robot pose is described with partciles not gaussian, each particle carries independent gaussians for each landmark (dont have to update a joint distribution, independent of the total number of particles, constant per particle). One small gaussian per landmark, so you only update one, reuse the rest of the binary tree, you get log time update (uses each leaf node to store the gaussiand for one landmark).

fast slam is a mix of parametric and non-parametric distributions
robot pose:
We use particles to represent the robot's trajectory, non parametric distribution that allows a multi-nodal distribution

landmark positions:
parametric model, uses gaussian for each landmark via ekf

MAPPING PROBLEM:

The landmark pose estimators p(θk | st, zt, ut, nt) are realized by Kalman filters, using separate filters for different landmarks. Because the landmark estimates are conditioned on the path estimate, each particle in the particle filter has its own, local landmark estimates. 

We sample many possible robot paths (using particle filter), and for each path do this:
If we had knowledge of the robot's path st (through an oracle) this would be just a mapping problem, which renders the individual landmark measurements independently. Once you know where the robot was when it made its observations, the measurements of the different landmarks no longer depend on each other. The problem of determining landmark locations could be decoupled into K estimations problems, one for each landmark.

nt ∈ {1, . . . , K} is the index of the landmark perceived at time t. The variable nt is often referred to as correspondence. Most theoretical work in the literature assumes knowledge of the correspondence or, put differently, that landmarks are uniquely identifiable -> with aruco (augmented reality university of cordoba, grid size nXn bits, total number of markers, a bit is either 0 (black, 0,0,0 rgb) or 1 (white, 255,255,255 rgb))  markers this problem dissapears, we have a know data association case. Which lets us avoid harder pratical implementations where maximum likelihood estimators are used for estimating the correspondence on-the-fly, which work well if landmarks are spaced sufficiently far apart. The problem simplifies to ->  p(st, θ | zt, ut, nt).

FAST SLAM PROCESS To LOCALIZE THE ROBOT AND MAP THE ROOM:

1) INITIALIZATION:

At the start, the robot doesn’t know where it is or where the landmarks are, so it starts with multiple particles to represent a wide range of possible trajectories and maps.

2) MOTION UPDATE:

As the robot moves, each particle updates its own pose (position and orientation).The motion model (which includes some uncertainty) is used to predict the robot's new pose for each particle.

3)MAPPING:

Each particle also observes landmarks in the environment via its sensors (e.g., cameras, LIDAR).For each observed landmark, the algorithm must determine which landmark the particle has seen -> This is the data association or correspondence problem, doesnt exist in our case, aruco markers.If the particle has seen the landmark before, it updates the landmark's location in the map.If the particle has not seen the landmark before, it adds a new landmark to the map.

FastSLAM handles data association by assuming that the robot's pose is known (for each particle), so it can independently update each landmark’s position using the information from the robot's sensors.

4) RESAMPLING:

After each update, particles that fit the robot's observations well (i.e., those that have a high likelihood) are re-sampled, creating more particles that represent the most likely paths.

5) FINAL ESTIMATION:

Over time, as the robot moves and collects more data, the particles converge, and the map and trajectory estimates become more accurate.


TYPES OF CONSTRAINTS IN SLAM:

Odometry constraints
Between st and st+1 ​: based on how far the robot thinks it moved.

Observation constraints
Between a pose st and a landmark thetak : based on how the robot saw something.

Loop closure constraints
When the robot revisits a known place — it adds a new constraint between distant poses, tightening the whole graph.

RAO-BLACKWELL THEOREM

At its core, the Rao-Blackwell theorem says: If you want to estimate something, it's better (or at least not worse) to: Sample only part of the random variables, and Compute the rest analytically (i.e., using math, not randomness), rather than sampling all of them together.

Sampling is noisy — more sampling means more variance (randomness). So if you can do math instead of sampling, the result is more stable and accurate.

Rao-Blackwellized approach (what FastSLAM does)
✅ Sample only the robot's pose (through particles).

✅ For each particle, compute the landmark locations analytically using a Kalman Filter (KF).

This means:

You're not randomly guessing landmark locations.

You're calculating them precisely, conditioned on where the particle says the robot is.

→ Less variance, faster convergence, better accuracy.

FIDUCIAL MARKERS / ARUCO:

visual reference object, usually a high-contrast, easily detectable shape—that a computer vision system can use to recognize position and orientation in space.

from the known size and design of the marker, the system can calculate where the camera is located (position) and which way it's facing (orientation)


